{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2e5dc9-20fe-4b57-be4e-6487300fbca3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Graph Library (DGL) queues model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40dae6-610d-4d02-b06c-b53f4af86cf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf53a7e-210a-48d6-9420-85ce6782d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"V2.2.1-queues.ipynb\"\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import linalg as LA\n",
    "import wandb\n",
    "from dgl.data import DGLDataset\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data.utils import makedirs, save_info, load_info, split_dataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "from torchmetrics.regression import SymmetricMeanAbsolutePercentageError\n",
    "from torchmetrics.regression import WeightedMeanAbsolutePercentageError\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from datanetAPI import DatanetAPI\n",
    "import requests\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import math\n",
    "import random\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0d904b-d2b1-4540-bc9f-c782f34744ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = '/data/escenari-slicing/samples-UPC/processed-100-v2.2.1'\n",
    "#save_dataset_path = './V2.2.1-100-queues'\n",
    "#save_model_path = './V2.2.1-model-100-dataset-inputgraphqueues'\n",
    "#dataset_name=\"Slicing-V2.2.1-100-queues\"\n",
    "\n",
    "\n",
    "dataset_path = '/data/escenari-slicing/samples-UPC/2.2.1-3kprocessed'\n",
    "save_model_path = './V2.2.1-model-100-dataset-inputgraphqueues01302024075531'\n",
    "save_dataset_path = './V2.2.1-3k'\n",
    "dataset_name=\"Slicing-V2.2.1-3k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef1f91-4940-4ecd-b2d5-f0c117ff4db6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfb77f7-00e0-4d00-be4f-9a515603b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlicingDataset(DGLDataset):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_dir : str\n",
    "        Specifying the directory that will store the\n",
    "        downloaded data or the directory that\n",
    "        already stores the input data.\n",
    "    save_dir : str\n",
    "        Directory to save the processed dataset.\n",
    "        Default: the value of `raw_dir`\n",
    "    force_reload : bool\n",
    "        Whether to reload the dataset. Default: False\n",
    "    verbose : bool\n",
    "        Whether to print out progress information\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, \n",
    "                 name=\"default_name\", \n",
    "                 raw_dir=None, \n",
    "                 save_dir=None, \n",
    "                 force_reload=False):\n",
    "        self.tool = DatanetAPI(raw_dir, shuffle=False)\n",
    "        super(SlicingDataset, self).__init__(\n",
    "            name=name, \n",
    "            raw_dir=raw_dir, \n",
    "            save_dir=save_dir, \n",
    "            force_reload=force_reload)\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        it = iter(self.tool)\n",
    "        self.graphs = []\n",
    "        for s in tqdm(it, total=len(self.tool.get_available_files()*7)):\n",
    "            G = nx.DiGraph(s.get_topology_object().copy())\n",
    "            R = s.get_routing_matrix()\n",
    "            T = s.get_traffic_matrix() \n",
    "            D = s.get_performance_matrix()\n",
    "            P = s.get_port_stats()\n",
    "            S = s.get_slices()\n",
    "            D_G = nx.DiGraph()\n",
    "\n",
    "            #AvgBw_sum calculation\n",
    "            AvgBw_sum = np.zeros((len(G.nodes),len(G.nodes)))\n",
    "            for src in range(G.number_of_nodes()):\n",
    "                for dst in range(G.number_of_nodes()):\n",
    "                    route = R[src,dst]\n",
    "                    if route:\n",
    "                        for index, node in enumerate(route):\n",
    "                            next_node_index = index + 1\n",
    "                            if next_node_index < len(route):\n",
    "                                for f_id in range(len(T[src, dst]['Flows'])):\n",
    "                                    if T[src, dst]['Flows'][f_id]['AvgBw'] != 0 and T[src, dst]['Flows'][f_id]['PktsGen'] != 0:\n",
    "                                        AvgBw_sum[node][route[next_node_index]] += T[src, dst]['Flows'][f_id]['AvgBw']\n",
    "\n",
    "            reservations_embb = np.zeros((len(G.nodes),len(G.nodes)))\n",
    "            reservations_urllc = np.zeros((len(G.nodes),len(G.nodes)))\n",
    "            reservations_mmtc = np.zeros((len(G.nodes),len(G.nodes)))\n",
    "            for slice in S:\n",
    "                for flow in slice[\"flows\"]:\n",
    "                    route = literal_eval(flow[\"path\"])\n",
    "                    for index, node in enumerate(route):\n",
    "                        next_node_index = index + 1\n",
    "                        if next_node_index < len(route):\n",
    "                            v_max = float(flow[\"bandwidth\"])*1.20 \n",
    "                            v_min = float(flow[\"bandwidth\"])*0.80\n",
    "                            if (slice[\"type\"] == \"eMBB\"):    \n",
    "                                reservations_embb[node][route[next_node_index]] += v_min+slice[\"delta\"]*(v_max-v_min)\n",
    "                            elif (slice[\"type\"] == \"URLLC\"):\n",
    "                                reservations_urllc[node][route[next_node_index]] += v_min+slice[\"delta\"]*(v_max-v_min)\n",
    "                            else:\n",
    "                                reservations_mmtc[node][route[next_node_index]] += v_min+slice[\"delta\"]*(v_max-v_min)\n",
    "            for src in range(G.number_of_nodes()):\n",
    "                for dst in range(G.number_of_nodes()):\n",
    "                    if src != dst:\n",
    "                        if G.has_edge(src, dst):\n",
    "                            \n",
    "                            D_G.add_node('l_{}_{}'.format(src, dst),\n",
    "                                capacity=torch.tensor(G.edges[src, dst]['bandwidth']),\n",
    "                                utilization=torch.tensor(P[src][dst][\"utilization\"]),\n",
    "                                avgPacketSize=torch.tensor(P[src][dst][\"avgPacketSize\"]),\n",
    "                                offeredTrafficIntensity=torch.tensor(AvgBw_sum[src][dst]/s.get_srcdst_link_bandwidth(src,dst)),\n",
    "                                nodeType=torch.tensor(0)\n",
    "                                )\n",
    "                                    \n",
    "                        for f_id in range(len(T[src, dst]['Flows'])):\n",
    "                            if T[src, dst]['Flows'][f_id]['AvgBw'] != 0 and T[src, dst]['Flows'][f_id]['PktsGen'] != 0:\n",
    "                                D_G.add_node('p_{}_{}_{}'.format(src, dst, f_id),\n",
    "                                    traffic=torch.tensor(T[src, dst]['Flows'][f_id]['AvgBw']),\n",
    "                                    packets=torch.tensor(T[src, dst]['Flows'][f_id]['PktsGen']),\n",
    "                                    delay=torch.tensor(D[src, dst]['Flows'][f_id]['AvgDelay']),\n",
    "                                    jitter=torch.tensor(D[src, dst]['Flows'][f_id]['Jitter']),\n",
    "                                    pathLength=torch.tensor(len(R[src,dst])),\n",
    "                                    drops=torch.tensor(D[src, dst]['AggInfo']['PktsDrop']/T[src, dst]['Flows'][f_id]['PktsGen']),\n",
    "                                    delta=torch.tensor(slice[\"delta\"]),\n",
    "                                    nodeType=torch.tensor(1)\n",
    "                                    )\n",
    "                                for h_1, h_2 in [R[src, dst][i:i + 2] for i in range(0, len(R[src, dst]) - 1)]:\n",
    "                                    D_G.add_edge('p_{}_{}_{}'.format(src, dst, f_id), 'l_{}_{}'.format(h_1, h_2), edgeType=torch.tensor(0)) #traverses\n",
    "                                    D_G.add_edge('l_{}_{}'.format(h_1, h_2), 'p_{}_{}_{}'.format(src, dst, f_id), edgeType=torch.tensor(1)) #composes\n",
    "\n",
    "                                    for idx, queue in enumerate(P[h_1][h_2][\"qosQueuesStats\"]):\n",
    "                                        weight = G.nodes[h_1]['schedulingWeights']\n",
    "                                        avgDelay = 0\n",
    "                                        maxDelay = 0\n",
    "                                        aOTI = 0\n",
    "                                        #sCT = 0\n",
    "                                        sliceType = None\n",
    "                                        sliceNumber = None\n",
    "                                        calculatedLosses = 0\n",
    "                                        AvgBwQueue_sum = 0\n",
    "                                        if weight != \"-\":\n",
    "                                            port = G[h_1][h_2]['port']\n",
    "                                            if (type(weight) != int):\n",
    "                                                weight = weight.split(\";\")[port]\n",
    "                                                if (type(weight) != int):\n",
    "                                                    weight = weight.split(\",\")[idx]\n",
    "                                            if (idx < len(G.nodes[h_1]['tosToQoSqueue'].split(\";\"))-1): #last is unused  \n",
    "                                                #Save scheduling weights of the queue\n",
    "                                                origins = list(map(int,G.nodes[h_1]['tosToQoSqueue'].split(\";\")[idx].split(\",\")))\n",
    "\n",
    "                                                if queue['utilization'] > 0 and float(weight) > 0.001:  \n",
    "                                                    for slice in S:\n",
    "                                                        for flow in slice[\"flows\"]:\n",
    "                                                            if int(flow[\"origin_node\"]) in origins:\n",
    "                                                                sliceType = slice[\"type\"]\n",
    "                                                                sliceNumber = slice[\"number\"]\n",
    "                                                                AvgBwQueue_sum += T[int(flow['origin_node']), int(flow['destination'])]['Flows'][0]['AvgBw']\n",
    "                                                        if sliceType is not None:\n",
    "                                                            break\n",
    "                                                        else:\n",
    "                                                            AvgBwQueue_sum = 0\n",
    "                                            \n",
    "                                            trafficPortion = float(s.get_srcdst_link_bandwidth(h_1,h_2))*(float(weight)/100)\n",
    "                                            aOTI = AvgBwQueue_sum/trafficPortion\n",
    "\n",
    "                                            maxDelay = 31*queue['avgPacketSize']/trafficPortion\n",
    "                                            if aOTI >= 1:\n",
    "                                                avgDelay = maxDelay\n",
    "                                            else: #aOTI < 1\n",
    "                                                avgDelay = min(queue['avgPacketSize']/trafficPortion*(1/(1-aOTI)),maxDelay)\n",
    "                                            if aOTI <= 1:\n",
    "                                                calculatedLosses = 0\n",
    "                                            else: # aOTI > 1\n",
    "                                                calculatedLosses = (AvgBwQueue_sum-trafficPortion)/AvgBwQueue_sum\n",
    "                                        else:\n",
    "                                            weight = 100\n",
    "                                        if s.get_srcdst_link_bandwidth(h_1,h_2) > 0 and maxDelay > 0:\n",
    "                                            D_G.add_node('q_{}_{}_{}'.format(h_1, h_2, idx),\n",
    "                                                weight=torch.tensor(float(weight)),\n",
    "                                                utilization=torch.tensor(queue['utilization']),\n",
    "                                                #aOTI=torch.tensor(aOTI),\n",
    "                                                calculatedLosses=torch.tensor(calculatedLosses),\n",
    "                                                maxDelay=torch.tensor(maxDelay),\n",
    "                                                nodeType=torch.tensor(2)\n",
    "                                                )\n",
    "                                            if sliceType is not None:\n",
    "                                                D_G.add_edge('p_{}_{}_{}'.format(src, dst, f_id), 'q_{}_{}_{}'.format(h_1, h_2, idx), edgeType=torch.tensor(2)) #uses\n",
    "                                                D_G.add_edge('q_{}_{}_{}'.format(h_1, h_2, idx), 'p_{}_{}_{}'.format(src, dst, f_id), edgeType=torch.tensor(3)) #serves\n",
    "                                                D_G.add_edge('l_{}_{}'.format(h_1, h_2), 'q_{}_{}_{}'.format(h_1, h_2, idx), edgeType=torch.tensor(4)) #hosts\n",
    "                                                D_G.add_edge('q_{}_{}_{}'.format(h_1, h_2, idx), 'l_{}_{}'.format(h_1, h_2), edgeType=torch.tensor(5)) #resides\n",
    "                                            \n",
    "            D_G.remove_nodes_from([node for node, in_degree in D_G.in_degree() if in_degree == 0])\n",
    "            D_G.remove_nodes_from([node for node, out_degree in D_G.out_degree() if out_degree == 0])\n",
    "\n",
    "            g = dgl.from_networkx(D_G, node_attrs=[\"nodeType\"])\n",
    "\n",
    "            nodeTypes = nx.get_node_attributes(D_G, 'nodeType')\n",
    "            nodes = D_G.nodes\n",
    "            g.ndata[dgl.NTYPE] = torch.stack([nodeTypes[e] for e in nodes])\n",
    "            g.ndata[dgl.NID] = torch.tensor([*range(0,len(D_G.nodes))])\n",
    "\n",
    "            edgeTypes = nx.get_edge_attributes(D_G, 'edgeType')\n",
    "            edges = D_G.edges\n",
    "            g.edata[dgl.ETYPE] = torch.stack([edgeTypes[e] for e in edges])\n",
    "            g.edata[dgl.EID] = torch.tensor([*range(0,len(D_G.edges))])\n",
    "            g = dgl.to_heterogeneous(g, ['link','path','queue'], ['traverses','composes', 'uses', 'serves', 'hosts', 'resides'])\n",
    "\n",
    "            capacities, utilizations, avgPacketSizes, offeredTrafficIntensities, nodeTypesLink = ([] for i in range(5))\n",
    "            \n",
    "            traffics, packets, delays, jitters, pathLengths, drops, deltas, nodeTypesPath = ([] for i in range(8))\n",
    "\n",
    "            weights, queueUtilizations, calculatedLosses, maxDelays, nodeTypesQueue  = ([] for i in range(5))\n",
    "            \n",
    "            for node in D_G.nodes(data=True):\n",
    "                if node[1][\"nodeType\"] == 0: #LINK               \n",
    "                    capacities.append(node[1][\"capacity\"])\n",
    "                    utilizations.append(node[1][\"utilization\"])\n",
    "                    avgPacketSizes.append(node[1][\"avgPacketSize\"])\n",
    "                    offeredTrafficIntensities.append(node[1][\"offeredTrafficIntensity\"])\n",
    "                    nodeTypesLink.append(node[1][\"nodeType\"])\n",
    "                    \n",
    "                elif node[1][\"nodeType\"] == 1: #FLOW/PATH\n",
    "                    traffics.append(node[1][\"traffic\"])\n",
    "                    packets.append(node[1][\"packets\"])\n",
    "                    delays.append(node[1][\"delay\"]) #TO PREDICT\n",
    "                    jitters.append(node[1][\"jitter\"]) #TO PREDICT\n",
    "                    drops.append(node[1][\"drops\"]) #TO PREDICT    \n",
    "                    pathLengths.append(node[1][\"pathLength\"])\n",
    "                    deltas.append(node[1][\"delta\"])\n",
    "                    nodeTypesPath.append(node[1][\"nodeType\"])\n",
    "                    \n",
    "                else : #if node[1][\"nodeType\"] == 2: #QUEUE\n",
    "                    weights.append(node[1][\"weight\"])\n",
    "                    queueUtilizations.append(node[1][\"utilization\"])\n",
    "                    calculatedLosses.append(node[1][\"calculatedLosses\"])\n",
    "                    maxDelays.append(node[1][\"maxDelay\"])\n",
    "                    nodeTypesQueue.append(node[1][\"nodeType\"])\n",
    "\n",
    "            #create tensors\n",
    "            g.nodes[\"link\"].data[\"capacity\"] = torch.stack(capacities)\n",
    "            g.nodes[\"link\"].data[\"utilization\"] = torch.stack(utilizations)\n",
    "            g.nodes[\"link\"].data[\"avgPacketSize\"] = torch.stack(avgPacketSizes)\n",
    "            g.nodes[\"link\"].data[\"offeredTrafficIntensity\"] = torch.stack(offeredTrafficIntensities)\n",
    "            g.nodes[\"link\"].data[\"nodeType\"] = torch.stack(nodeTypesLink)\n",
    "            \n",
    "            g.nodes[\"path\"].data[\"traffic\"] = torch.stack(traffics)\n",
    "            g.nodes[\"path\"].data[\"packets\"] = torch.stack(packets)\n",
    "            g.nodes[\"path\"].data[\"delay\"] = torch.stack(delays)\n",
    "            g.nodes[\"path\"].data[\"jitter\"] = torch.stack(jitters)\n",
    "            g.nodes[\"path\"].data[\"drops\"] = torch.stack(drops)\n",
    "            g.nodes[\"path\"].data[\"pathLength\"] = torch.stack(pathLengths)\n",
    "            g.nodes[\"path\"].data[\"delta\"] = torch.stack(deltas)\n",
    "            g.nodes[\"path\"].data[\"nodeType\"] = torch.stack(nodeTypesPath)\n",
    "\n",
    "            g.nodes[\"queue\"].data[\"weight\"] = torch.stack(weights)\n",
    "            g.nodes[\"queue\"].data[\"queueUtilization\"] = torch.stack(queueUtilizations)\n",
    "            g.nodes[\"queue\"].data[\"calculatedLosses\"] = torch.stack(calculatedLosses)\n",
    "            g.nodes[\"queue\"].data[\"maxDelay\"] = torch.stack(maxDelays)\n",
    "            g.nodes[\"queue\"].data[\"nodeType\"] = torch.stack(nodeTypesQueue)\n",
    "\n",
    "            self.graphs.append(g)\n",
    "        self.save()\n",
    "        \n",
    "    def getGraphs(self):\n",
    "        return self.graphs\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Get graph and label by index\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            Item index\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (dgl.DGLGraph)\n",
    "        \"\"\"\n",
    "        return self.graphs[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of graphs in the dataset, *7 because the samples are grouped in groups of 7\"\"\"\n",
    "        return 3492 #len(self.tool.get_available_files())*79\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        # batch is a list of tuple (graph, label)\n",
    "        graphs = [e[0] for e in batch]\n",
    "        g = dgl.batch(graphs)\n",
    "        labels = [e[1] for e in batch]\n",
    "        labels = torch.stack(labels, 0)\n",
    "        return g\n",
    "\n",
    "    def save(self):\n",
    "        # save graphs and labels\n",
    "        graph_path = os.path.join(self.save_dir, 'dgl_graph.bin')\n",
    "        save_graphs(graph_path, self.graphs)\n",
    "        \n",
    "    def load(self):\n",
    "        # load processed data from directory `self.save_path`\n",
    "        graph_path = os.path.join(self.save_dir, 'dgl_graph.bin')\n",
    "        self.graphs = load_graphs(graph_path)\n",
    "\n",
    "\n",
    "    def has_cache(self):\n",
    "        # check whether there is processed data in `self.save_path`\n",
    "        graph_path = os.path.join(self.save_dir, 'dgl_graph.bin')\n",
    "        return os.path.exists(graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45330206-2163-469d-8cfb-62b9810ee336",
   "metadata": {},
   "source": [
    "1. Obtenir graph base dirigit de cada sample  \n",
    "2. Afegir atributs desitjats al graf\n",
    "3. Carregar-lo a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19508292-17b7-4566-90b0-d46bfcd3574f",
   "metadata": {},
   "source": [
    "## Dataloader initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authorized-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "dataset = SlicingDataset(\n",
    "    name=dataset_name,\n",
    "    raw_dir=dataset_path, \n",
    "    save_dir=save_dataset_path, \n",
    "    force_reload=False)\n",
    "\n",
    "dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587c23b-feef-438b-a106-c2d2bcad2c42",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e479cf5-5291-4163-a09f-6f8cc280c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_validation, ds_test = split_dataset(dataset,[0.8,0.1,0.1], random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ad39e3-1a44-4204-a171-d7bd35052733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(\"Slicing-V2.2.1-3k\", num_graphs=3492, save_path=./V2.2.1-3k/Slicing-V2.2.1-3k)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4687eca-e8fa-41a6-889a-0e5d616d43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444\n",
      "523\n",
      "525\n"
     ]
    }
   ],
   "source": [
    "#print length of the datasets\n",
    "print(len(ds_train))\n",
    "print(len(ds_validation))\n",
    "print(len(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acca5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2eab5f-a770-4ad0-a139-73e581976259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        aggregation_function = 'sum'\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            'traverses': dglnn.GraphConv(in_feats, hid_feats),\n",
    "            'composes': dglnn.GraphConv(in_feats, hid_feats),\n",
    "            'uses': dglnn.GraphConv(in_feats, hid_feats),\n",
    "            'serves': dglnn.GraphConv(in_feats, hid_feats),\n",
    "            'hosts': dglnn.GraphConv(in_feats, hid_feats),\n",
    "            'resides': dglnn.GraphConv(in_feats, hid_feats)\n",
    "            },\n",
    "            aggregate=aggregation_function)\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            'traverses': dglnn.GraphConv(hid_feats, out_feats),\n",
    "            'composes': dglnn.GraphConv(hid_feats, out_feats),\n",
    "            'uses': dglnn.GraphConv(hid_feats, out_feats),\n",
    "            'serves': dglnn.GraphConv(hid_feats, out_feats),\n",
    "            'hosts': dglnn.GraphConv(hid_feats, out_feats),\n",
    "            'resides': dglnn.GraphConv(hid_feats, out_feats)\n",
    "            },\n",
    "            aggregate=aggregation_function)\n",
    "  \n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of the nodes\n",
    "        \n",
    "        #print(inputs)\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: torch.nn.functional.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        h = {k: torch.nn.functional.relu(v) for k, v in h.items()}\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153d402e-9d6a-4fc1-8d78-94263599503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RGCN(\n",
       "  (conv1): HeteroGraphConv(\n",
       "    (mods): ModuleDict(\n",
       "      (traverses): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (composes): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (uses): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (serves): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (hosts): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (resides): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "    )\n",
       "  )\n",
       "  (conv2): HeteroGraphConv(\n",
       "    (mods): ModuleDict(\n",
       "      (traverses): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (composes): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (uses): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (serves): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (hosts): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (resides): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RGCN(4,10,3)\n",
    "model.to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd6e533-d203-43f1-8ad6-6aa7a15728bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinFeatures(fs):\n",
    "    features = []\n",
    "    for feature in fs:\n",
    "        if feature == \"_ID\" or feature == \"nodeType\" or feature == \"delay\" or feature == \"drops\" or feature == \"jitter\":\n",
    "            continue\n",
    "        else:\n",
    "            features.append(fs[feature])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c362b776-d487-4f5c-addc-e42b0242a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformFeatures(g):\n",
    "    features = [\"delay\", \"drops\", \"jitter\", \n",
    "                \"capacity\", \"utilization\", \"avgPacketSize\", \"offeredTrafficIntensity\", \n",
    "                \"traffic\", \"packets\", \"pathLength\", \"delta\",\n",
    "                \"weight\", \"queueUtilization\", \"queueLosses\", \"queueDelay\"]\n",
    "    for feature in features:\n",
    "        #transformation of output features\n",
    "        if feature == \"delay\":\n",
    "            g.nodes['path'].data['delay'] = torch.clamp(g.nodes['path'].data['delay'], max=0.0230716) #IQR 90\n",
    "            g.nodes['path'].data['delay'] = (g.nodes['path'].data['delay']-0.00001)/(0.0230716-0.00001)\n",
    "            \n",
    "        elif feature == \"drops\":\n",
    "            g.nodes['path'].data['drops'] = (g.nodes['path'].data['drops']+15)/15\n",
    "            \n",
    "        elif feature == \"jitter\":\n",
    "            g.nodes['path'].data['jitter'] = torch.clamp(g.nodes['path'].data['jitter'], max=0.000022) #IQR\n",
    "            g.nodes['path'].data['jitter'] = (g.nodes['path'].data['jitter']+10)/(0.000022+10)\n",
    "\n",
    "        \n",
    "        #transformation of input link features\n",
    "        elif feature == \"capacity\":\n",
    "            g.nodes['link'].data['capacity'] = (g.nodes['link'].data['capacity']-25000000)/(450000000-25000000)\n",
    "            \n",
    "        elif feature == \"utilization\":\n",
    "            g.nodes['link'].data['utilization'] = (g.nodes['link'].data['utilization']-0)/(1-0)\n",
    "            \n",
    "        elif feature == \"avgPacketSize\":\n",
    "            g.nodes['link'].data['avgPacketSize'] = torch.clamp(g.nodes['link'].data['avgPacketSize'], min=0) #some negative values found in the small dataset\n",
    "            g.nodes['link'].data['avgPacketSize'] = (g.nodes['link'].data['avgPacketSize']-0)/(15500.53-0)\n",
    "            \n",
    "        elif feature == \"offeredTrafficIntensity\":\n",
    "            g.nodes['link'].data['offeredTrafficIntensity'] = (g.nodes['link'].data['offeredTrafficIntensity']-0)/(4.59-0)\n",
    "\n",
    "        \n",
    "        #transformation of input path features\n",
    "        elif feature == \"traffic\":\n",
    "            g.nodes['path'].data['traffic'] = (g.nodes['path'].data['traffic']-249526)/(22531500-249526)\n",
    "            \n",
    "        elif feature == \"packets\":\n",
    "            g.nodes['path'].data['packets'] = (g.nodes['path'].data['packets']-623.86)/(3772.93-623.86)\n",
    "            \n",
    "        elif feature == \"pathLength\":\n",
    "            g.nodes['path'].data['pathLength'] = (g.nodes['path'].data['pathLength']-4)/(14-4)\n",
    "            \n",
    "        elif feature == \"delta\":\n",
    "            g.nodes['path'].data['delta'] = (g.nodes['path'].data['delta']-0.001)/(0.998-0.001)\n",
    "\n",
    "        \n",
    "        #transformation of input queue features\n",
    "        elif feature == \"weight\":\n",
    "            g.nodes['queue'].data['weight'] = (g.nodes['queue'].data['weight']-0)/(100-0)\n",
    "            \n",
    "        elif feature == \"queueUtilization\":\n",
    "            g.nodes['queue'].data['queueUtilization'] = (g.nodes['queue'].data['queueUtilization']-0.00001)/(1.00006-0.00001)\n",
    "            \n",
    "        elif feature == \"calculatedLosses\":\n",
    "            continue\n",
    "            \n",
    "        elif feature == \"maxDelay\":\n",
    "            g.nodes['queue'].data['maxDelay'] = torch.clamp(g.nodes['queue'].data['maxDelay'], max=4.96) #IQR\n",
    "            g.nodes['queue'].data['maxDelay'] = (g.nodes['queue'].data['maxDelay']-0.00003)/(4.96-0.00003)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b984df86-55cf-4376-a470-3a02e5d1b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smape(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    \n",
    "    :param actual: list of actual values\n",
    "    :param predicted: list of predicted values\n",
    "    :return: SMAPE as a percentage\n",
    "    \"\"\"\n",
    "    # Ensure actual and predicted lists have the same length\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"Input lists must have the same length\")\n",
    "    \n",
    "    # Calculate SMAPE\n",
    "    n = len(actual)\n",
    "    total_error = 0\n",
    "    for a, p in zip(actual, predicted):\n",
    "        if p == 0 and a == 0:\n",
    "            continue\n",
    "        else:\n",
    "            total_error += 2 * (abs(a - p) / (abs(a) + abs(p)))\n",
    "    \n",
    "    smape = (total_error / n)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-colon",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "altered-recommendation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RGCN(\n",
       "  (conv1): HeteroGraphConv(\n",
       "    (mods): ModuleDict(\n",
       "      (traverses): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (composes): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (uses): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (serves): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (hosts): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "      (resides): GraphConv(in=4, out=10, normalization=both, activation=None)\n",
       "    )\n",
       "  )\n",
       "  (conv2): HeteroGraphConv(\n",
       "    (mods): ModuleDict(\n",
       "      (traverses): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (composes): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (uses): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (serves): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (hosts): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "      (resides): GraphConv(in=10, out=3, normalization=both, activation=None)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-blanket",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapes_delay = []\n",
    "mapes_not_loss = []\n",
    "mapes_jitter = []\n",
    "\n",
    "smapes_delay = []\n",
    "smapes_not_loss = []\n",
    "smapes_jitter = []\n",
    "\n",
    "metric = MeanAbsolutePercentageError()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for g in ds_test.dataset[0]:\n",
    "        \n",
    "        g = transformFeatures(g)\n",
    "        \n",
    "        link_feats = torch.transpose(torch.stack(joinFeatures(g.nodes['link'].data)),0,1)\n",
    "        path_feats = torch.transpose(torch.stack(joinFeatures(g.nodes['path'].data)),0,1)\n",
    "        queue_feats = torch.transpose(torch.stack(joinFeatures(g.nodes['queue'].data)),0,1)\n",
    "        labels = torch.stack((g.nodes['path'].data['delay'], g.nodes['path'].data['drops'], g.nodes['path'].data['jitter']))\n",
    "        node_features = {'link': link_feats, 'path': path_feats, 'queue': queue_feats}\n",
    "        logits = model(g, node_features)['path']\n",
    "        logits = torch.transpose(logits,0,1)\n",
    "        \n",
    "        mape_delay = calculate_smape((logits[0]*0.0230716)+0.00001, (labels[0]*0.0230716)+0.00001)*100\n",
    "        mapes_delay.append(mape_delay.item())\n",
    "\n",
    "        mape_not_loss = calculate_smape((logits[1]*15-15), (labels[1]*15-15))*100\n",
    "        mapes_not_loss.append(mape_not_loss.item())\n",
    "\n",
    "        mape_jitter = calculate_smape(logits[2]*0.000022, labels[2]*0.000022)*100\n",
    "        mapes_jitter.append(mape_jitter.item())\n",
    "\n",
    "        \"\"\"smape_delay = calculate_smape(logits[0], labels[0])*100\n",
    "        smapes_delay.append(smape_delay.item())\n",
    "\n",
    "        smape_not_loss = calculate_smape(logits[1], labels[1])*100\n",
    "        smapes_not_loss.append(smape_not_loss.item())\n",
    "\n",
    "        smape_jitter = calculate_smape(logits[2], labels[2])*100\n",
    "        smapes_jitter.append(smape_jitter.item())\"\"\"\n",
    "        \n",
    "print(\"MAPE delay queue: \"+str(sum(mapes_delay)/len(mapes_delay)))\n",
    "print(\"MAPE not loss queue: \"+str(sum(mapes_not_loss)/len(mapes_not_loss)))\n",
    "print(\"MAPE jitter: \"+str(sum(mapes_jitter)/len(mapes_jitter)))\n",
    "\n",
    "\n",
    "#print(\"sMAPE delay queue: \"+str(sum(smapes_delay)/len(smapes_delay)))\n",
    "#print(\"sMAPE not loss queue: \"+str(sum(smapes_not_loss)/len(smapes_not_loss)))\n",
    "#print(\"sMAPE jitter: \"+str(sum(smapes_jitter)/len(smapes_jitter)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“pytorch”",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
